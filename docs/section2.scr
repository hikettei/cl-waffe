@begin(section)
@title(Extend library)

All features of cl-waffe is exported for users, users can extend it as they wish.

The first section describes defmodel/deftrainer which will be most used macros.

The rest sections describe defnode/defoptimizer/defdataset which will be a little difficult for users to understand.

@begin(section)
@title(defmodel)

To put it bluntly, what defmodel to cl-waffe is what class(nn.Modules): to PyTorch.

Internally, defmodel is a macro for just defining defstruct, but can be used like CLOS Style.

@cl:with-package[name="cl-waffe"](
@cl:doc(macro defmodel)
)

For example, defines seq2seq's encoder.
@begin[lang=lisp](code)
(defmodel Encoder (vocab-size embedding-dim hidden-size)
  :parameters ((embedding (Embedding vocab-size embedding-dim :pad-idx 0))
               (layer     (RNN embedding-dim hidden-size :num-layers 1)))
  :forward ((x)
	    (with-calling-layers x
	      (embedding x)
	      (layer x))))
@end[lang=lisp](code)

(defmodel Encoder (vocab-size embedding-dim hidden-size) ~) says, The constructor of it is (Encoder vocab-size embedding-dim hidden-size) And these parameters will be used when initializing :parameters.

:parameters have Parameters of each object, that is, each time model is initialized, (Embedding ~) and (RNN ~) are created and inserted to Encoder's embedding, layer.

:forward defines forward-step.

There is no need to define :backward as automatic differentiation is enabled inside the defmodel. That is, in defmodel's forward, @b(all calculations must be done in cl-waffe's APIs) otherwise computation nodes would be broken.

@begin(section)
@title(Initialize and call model)

Let's create encoder and call forward.

@begin[lang=lisp](code)
(setq model (Encoder 10 16 10))
;[Model: ENCODER]

(call model (!ones `(10 10)))
;#Const((((-2.31... 3.048... ~ 2.551... -2.98...)         
;                   ...
;         (-2.31... 3.048... ~ 2.551... -2.98...))        
;                 ...
;        ((-2.31... 3.048... ~ 2.551... -2.98...)         
;                   ...
;         (-2.31... 3.048... ~ 2.551... -2.98...))) :mgl t :shape (10 10 10))

(backward (!sum *))
; NIL
; Backward process is done correctly!
@end[lang=lisp](code)
@end(section)

@begin(section)
@title(CLOS Style)

(This is available in other macros as well.)

This is obviously but you can define method for each cl-waffe objects.

Each parameter can be accessed by using slot-value or each inherent accessor.

@begin[lang=lisp](code)

(defmethod print-object ((model Encoder) stream)
     (format stream "[Seq2Seq Encoder which contains: ~a and ~a]"
                    (slot-value model 'embedding)
		    (encoder-layer model)))
		    
(print model)
;[Seq2Seq Encoder which contains: [Model: EMBEDDING] and [Model: RNN]]
@end[lang=lisp](code)

See also for more APIs: @link[uri="./cl-waffe.html#1-defmodel"](document)
@end(section)
@end(section)

@begin(section)
@title(deftrainer)

See: @link[uri="./cl-waffe.html#trainer"](document).

@end(section)

@begin(section)
@title(defoptimizer)

See: @link[uri="./cl-waffe.html#optimizer"](document).
@end(section)

@begin(section)
@title(defnode)

defnode is a macro for defining a computation node itself in contrast to defmodel defining calculations using operators defined by defnode.

defnode requires :forward :backward to be fulfilled.

cl-waffe's APIs aren't necessary to be used in each step of :forward :backward as long as WaffeTensor is returned.

For example, defining (!transpose1 ...) without using cl-waffe's APIs.
@begin[lang=lisp](code)
(defnode Transpose1Tensor (shape)
  :optimize t
  :parameters ((prev-shape nil) (shape shape))
  :forward ((x)
	    (setf (self prev-shape) (!shape x))
	    (with-facet (array ((value x) 'array :direction :input))
	      (sysconst (array-to-mat (numcl:transpose array)))))
  :backward ((dy)
	     (list (!transpose1 dy (self prev-shape)))))

(defun !transpose1 (x &rest result)
   (call (Transpose1Tensor (assure-tensor result)) (assure-tensor x)))

(setq a (!randn `(10 10)))
(setq a (!transpose1 a))
(print (cl-waffe::waffetensor-state a))
; [Node : TRANSPOSE1TENSOR]
; Backward created correctly.
@end[lang=lisp](code)

mgl-mat provides an macro @cl:param(with-facet) (@link[uri="https://github.com/melisgl/mgl-mat"](See original repos)), which is used to directly access cl's array etc.

In other example, defining dropout.
@begin[lang=lisp](code)
; An implementation of Inverted Dropout.
(defnode Dropout (&optional (dropout-rate 0.5))
  :document (with-usage "Dropout"
	      :note "Todo: docstring")
  :optimize t
  :parameters ((dropout-rate
		(if (and (> dropout-rate 0.0)
			 (< dropout-rate 1.0))
		    dropout-rate
		    (error "cl-waffe.nn: Dropout(x), x must be in the range of 0.0<x<1.0 where x is a single-float.")))
	       (mask T))
  :forward ((x)
	    (if (eql (self mask) T) ; is first call?
		(setf (self mask) (!zeros (!shape x))))
	    
	    (if *no-grad* ; predict mode
		x
		(progn
		  (!modify (self mask) :bernoulli (self dropout-rate))
		  (!modify (!mul (self mask) x) :*= (/ 1 (- 1 (self dropout-rate)))))))

  :backward ((dy)
	     (list (!mul (self mask) dy))))
@end[lang=lisp](code)

Tips: using T as a default parameter is convinient since cl-waffe's optimizer can detect discontinuities in the computation nodes.

See also for more APIs: @link[uri="./cl-waffe.html#2-defnode"](document)
@end(section)

@begin(section)
@title(defdataset)
See: @link[uri="./cl-waffe.html#datasets"](document).

Todo: parallelize/make its memory-usage less.

@end(section)
@end(section)