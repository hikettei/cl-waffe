
@begin(section)
@title(Neural Networks)

@begin(section)
@title(model-list)
Holds submodules in a list.

Model-List it contains are properly tracked by @cl:param(find-variables).

Note: This Layer is exported from Package @cl:param(cl-waffe).
@begin(section)
@title(Parameters)
@begin[lang=lisp](code)
(model-list list)
@end[lang=lisp](code)
@begin(deflist)

@def(list (list))
@term(an list of models)

@end(deflist)

This model can also be created by @cl:param(mlist)

@begin[lang=lisp](code)
(mlist models) ; -> [Model: MODEL-LIST]
@end[lang=lisp](code)
@end(section)

@begin(section)
@title(Forward)
@begin[lang=lisp](code)
(call (Model-List) index &rest args)
@end[lang=lisp](code)

Note that @cl:param(index) must be waffetensor.

To avoid this, @cl:param(mth) is available.

@begin[lang=lisp](code)
(call (mth 0 (Model-List)) &rest args)
@end[lang=lisp](code)

@begin(deflist)

@def(index (waffetensor of which data is fixnum))
@term(an index of models)

@def(args (list))
@term(arguments for index-th model)

@end(deflist)
@end(section)

@begin(section)
@title(Example)
@begin[lang=lisp](code)
(setq models (Model-List (list (linearlayer 10 1) (linearlayer 10 1))))
(call models (const 0) (!randn `(10 10)))
(call (mth 0 models) (!randn `(10 10)))
@end[lang=lisp](code)
@end(section)
@end(section)

@begin(section)
@title(Linearlayer)
Applies a linear transformation to the incoming data: @c((setq y (!add (!matmul x weight) bias)))

@begin(section)
@title(Parameters)
@begin[lang=lisp](code)
(LinearLayer in-features out-features &optional (bias T))
@end[lang=lisp](code)
@begin(deflist)

@def(in-features (fixnum))
@term(size of each input sample)
@def(out-features (fixnum))
@term(size of each output sample)
@def(bias (boolean))
@term(If set to nil, the layer will not learn an additive bias. default:t)

@end(deflist)
@end(section)

@begin(section)
@title(Shape)
@begin(deflist)

@def(Input)
@term(x (Tensor) where the x is the shape of (batch-size in-features))
@def(Output)
@term(Output: an tensor that applied linearlayer, where the tensor is the shape of (batch-size out-features))

@end(deflist)
@end(section)

@begin(section)
@title(Forward)
@begin[lang=lisp](code)
(call (LinearLayer 10 1) x)
@end[lang=lisp](code)

@begin(deflist)

@def(x)
@term(the input tensor)

@end(deflist)
@end(section)

@begin(section)
@title(Example)
@begin[lang=lisp](code)
(call (LinearLayer 10 1) (!randn `(10 10)))
@end[lang=lisp](code)
@end(section)
@end(section)

@begin(section)
@title(DenseLayer)
Calling LinearLayer, and activation specified in @cl:param(activation).

@begin(section)
@title(Parameters)
@begin[lang=lisp](code)
(DenseLayer in-features out-features &optional (bias t) (activation :relu))
@end[lang=lisp](code)
@begin(deflist)

@def(in-features (fixnum))
@term(size of each input sample)

@def(out-features (fixnum))
@term(size of each output sample)

@def(bias (boolean))
@term(If set to nil, the layer will not learn an additive bias. default:t)

@def(activation (keyword or function))
@term(activation are following: :relu :sigmoid :tanh, If set to function, that is called as an activation.)

@end(deflist)
@end(section)

@begin(section)
@title(Shape)
@begin(deflist)

@def(Input)
@term(x (Tensor) where the x is the shape of (batch-size in-features))
@def(Output)
@term(Output: an tensor that applied denselayer, where the tensor is the shape of (batch-size out-features))

@end(deflist)
@end(section)

@begin(section)
@title(Forward)
@begin[lang=lisp](code)
(call (DenseLayer 10 1) x)
@end[lang=lisp](code)

@begin(deflist)

@def(x)
@term(the input tensor)

@end(deflist)
@end(section)

@begin(section)
@title(Example)
@begin[lang=lisp](code)
(call (DenseLayer 10 1)  (!randn `(10 10)))
@end[lang=lisp](code)
@end(section)
@end(section)


@begin(section)
@title(Dropout)
@cl:with-package[name="cl-waffe.nn"](
@cl:doc(struct Dropout)
)
@end(section)

@begin(section)
@title(BatchNorm2d)
@cl:with-package[name="cl-waffe.nn"](
@cl:doc(struct BatchNorm2d)
)
@end(section)

@begin(section)
@title(LayerNorm)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@begin(section)
@title(Embedding)
@cl:with-package[name="cl-waffe.nn"](
@cl:doc(struct Embedding)
)
@end(section)

@begin(section)
@title(RNN)
@cl:with-package[name="cl-waffe.nn"](
@cl:doc(struct RNN)
)
@end(section)

@begin(section)
@title(LSTM)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@begin(section)
@title(GRU)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@begin(section)
@title(MaxPooling)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@begin(section)
@title(AvgPooling)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@begin(section)
@title(Conv1D)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@begin(section)
@title(Conv2D)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@begin(section)
@title(Transformer)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@begin(section)
@title(TransformerEncoderLayer)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@begin(section)
@title(TransformerDecoderLayer)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@begin(section)

@title(CrossEntropy)
@cl:with-package[name="cl-waffe.nn"](
@cl:doc(function cross-entropy)
)
@end(section)

@begin(section)
@title(SoftMaxCrossEntropy)
@cl:with-package[name="cl-waffe.nn"](
@cl:doc(function softmax-cross-entropy)
)
@end(section)

@begin(section)
@title(MSE)
@cl:with-package[name="cl-waffe.nn"](
@cl:doc(function mse)
)
@end(section)

@begin(section)
@title(L1Norm)
@cl:with-package[name="cl-waffe.nn"](

)
@end(section)

@begin(section)
@title(L2Norm)
@cl:with-package[name="cl-waffe.nn"](

)
@end(section)

@begin(section)
@title(BinaryCrossEntropy)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@begin(section)
@title(KLdivLoss)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@begin(section)
@title(CosineSimilarity)
@cl:with-package[name="cl-waffe.nn"](
)
@end(section)

@end(section)