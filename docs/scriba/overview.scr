
@begin(section)
@title(Overview)
@begin(section)
@title(About This Project)

@image[src="https://github.com/hikettei/cl-waffe/blob/main/docs/cl-waffe-logo.png?raw=true"]()
@image[src="https://github.com/hikettei/cl-waffe/actions/workflows/ci.yml/badge.svg"]()
This documentation provides an overview of the development and usage of cl-waffe, based on Common Lisp and mgl-mat.
The primary goal of this project is:
@begin(enum)
@item(Flexible And Efficient Platform in 99% Pure Common Lisp.)
@item(Make APIs Extensible as possible, enabling users not to depend the standard implementations.)
@item(Eazy to optimize with Inlined Function.)
@end(enum)
This framework is designed to be user-friendly first, enabling both beginners and experts in the field of AI to take advantage of capabilities of powerful programming language, Common Lisp.


‚ö†Ô∏è @b(The documentation is being rewritten and is currently only half complete.)
@b(

This framework is still under development and experimental. If you are thinking on using it in your products, It would be wiser to use other libraries. True, the author of cl-waffe is not a expert of AI. (Also, not having cuda gpus, I can't test my framework on cuda.))
@end(section)
@begin(section)
@title(Links)

@link[uri="https://github.com/hikettei/cl-waffe"](Official Github Repository)



@link[uri="https://hikettei.github.io/cl-waffe-docs/docs/overview.html"](The Documentation)



@link[uri="https://github.com/hikettei/cl-waffe/tree/main/tutorials/jp"](Tutorial Notebooks (Written in Japanese))



@link[uri="https://github.com/hikettei/cl-waffe/blob/main/benchmark/Result.md"](Benchmarks)
@end(section)
@begin(section)
@title(Workloads)

@begin(enum)
@item(Make Full optimized implementation of the standard nodes.)
@item(Save And Restore Models with keeping compatibility with npz.)
@item(üéâ release cl-waffe v0.1)
@item(Add more standard implementation of NNs, after the foundations are in place.)
@end(enum)
@end(section)
@begin(section)
@title(LLA Backend)

cl-waffe's matrix operations are performed via mgl-mat, and mgl-mat uses LLA. Accordingly, cl-waffe's performance hinges on mgl-mat and LLA's performance.
The most recommended one is OpenBLAS. Append following in your setup files (e.g.: ~/.roswell/init.lisp, ~/.sbclrc). For more details, visit the official repositories.
@link[uri="https://github.com/tpapp/lla"](LLA)
@link[uri="https://github.com/melisgl/mgl-mat"](mgl-mat)
@begin[lang=lisp](code)
(defvar *lla-configuration* '(:libraries ("/usr/local/opt/openblas/lib/libblas.dylib")))
@end[lang=lisp](code)
@end(section)
@begin(section)
@title(When Memory Heap Is Exhasted?)

The additional setting of dynamic-space-size would be required since training deep learning models consumes a lot of space.
For Example, Roswell and SLIME respectively.
@begin[lang=shell](code)
$ ros config set dynamic-space-size 4gb
@end[lang=shell](code)
@begin[lang=lisp](code)
(setq slime-lisp-implementations '(("sbcl" ("sbcl" "--dynamic-space-size" "4096"))))
@end[lang=lisp](code)
should work. However, Improving memory usage is one of my concerns.
@end(section)
@end(section)